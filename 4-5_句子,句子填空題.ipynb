{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"4-4.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"o2mpQV8GnKnQ","colab_type":"text"},"cell_type":"markdown","source":["# 全部文章中每個句子和單字分開的資料\n","\n"]},{"metadata":{"id":"-b4tfVr0nLwc","colab_type":"code","colab":{}},"cell_type":"code","source":["import pickle\n","with open(\"題目的斷句_CoreNLP.txt\",'rb') as fp:\n","    word_lists=pickle.load(fp)\n","\n","word_list=[]\n","for words in word_lists:\n","    word_list.append([i.lower() for i in words])\n","\n","print(word_list[7])\n","\n","#去標點\n","import re\n","import string\n","import nltk\n","from nltk.corpus import stopwords\n","import re\n","\n","\n","stop_words=stopwords.words('english')\n","\n","r='[’‘•!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~]+'\n","sentences_token=[]\n","for j in word_list:\n","    wordsfiltered=[]\n","    for a in j:\n","        i=nltk.word_tokenize(a)\n","        temp=[x for x in i if x not in stop_words and not re.search('[0-9]+',x) and not re.search(r,x) and '\\\\' not in x and len(x)>4]\n","        wordsfiltered.append(temp)\n","    sentences_token.append(wordsfiltered)\n","print(sentences_token[7])\n","\n","\n","#詞幹還原\n","lmtzr=nltk.WordNetLemmatizer()\n","array_lmtzr=[]\n","\n","for i in sentences_token:\n","    wordstoken=[] \n","    for j in i:\n","        temp=[]\n","        for word, tag in nltk.pos_tag(j):\n","            if tag.startswith('NN'):\n","                temp.append(lmtzr.lemmatize(word,pos='n'))\n","            elif tag.startswith('VB'):\n","                temp.append(lmtzr.lemmatize(word,pos='v'))\n","            elif tag.startswith('JJ'):\n","                temp.append(lmtzr.lemmatize(word,pos='a'))\n","            elif tag.startswith('R'):\n","                temp.append(lmtzr.lemmatize(word,pos='r'))\n","            else:\n","                temp.append(word)\n","        wordstoken.append(temp)\n","    array_lmtzr.append(wordstoken)\n","print(array_lmtzr[7])\n","\n","\n","#找wordnet還原\n","from nltk.corpus import wordnet\n","\n","parag_list=[]\n","for parag in array_lmtzr:\n","    sentence_list=[]\n","    for sentence in parag:\n","        word_list=[]\n","        for words in sentence:\n","            if wordnet.synsets(words):\n","                word_list.append(words)\n","        sentence_list.append(word_list)\n","    parag_list.append(sentence_list)\n","    \n","#存檔\n","import pickle\n","with open(\"句子單字斷開.txt\",'wb') as fp:\n","    pickle.dump(parag_list,fp)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"HhrZ8FOBnQ4n","colab_type":"text"},"cell_type":"markdown","source":["# **每個單字的句子的資料**"]},{"metadata":{"id":"p3qR4S4FnUq_","colab_type":"code","colab":{}},"cell_type":"code","source":["import pickle\n","with open('題目的斷句_CoreNLP.txt','rb') as fp:\n","    sentence_lists=pickle.load(fp)\n","with open(\"句子單字斷開.txt\",'rb') as fp:\n","    parag_text=pickle.load(fp)\n","    \n","parag_sent=[]\n","for i in range(len(parag_text)):\n","    sent=[]\n","    for j in parag_text[i]:\n","        sent.append(' '.join(j))\n","    parag_sent.append(sent)\n","print(' '.join(parag_sent[4789]))\n","\n","#讀EXCEL\n","import pandas as pd\n","push = pd.read_excel(\"單字推播after_del_level1&2.xlsx\",index_col=\"日期\")\n","\n","#一星題\n","with open(\"一星.txt\",'rb') as fp:\n","    X1=pickle.load(fp)\n","    print(X1)\n","\n","#單字的句子加入excel\n","yesterday=None\n","today_question=None\n","yesterday_question=None\n","sentences_one=[]\n","sentences_two=[]\n","sentences_three=[]\n","sentences_four=[]\n","sentences_five=[]\n","for today in push.index:\n","    today_word=words()\n","    numbers()\n","    today_sentences=sentences()\n","    \n","    print(today_word)\n","    print(today_sentences)\n","    print(today_question)\n","    print(yesterday_question)\n","    print(\"\")\n","    for x in range(5):\n","        if x==0:\n","            sentences_one.append(today_sentences[x])\n","        elif x==1:\n","            sentences_two.append(today_sentences[x])\n","        elif x==2:\n","            sentences_three.append(today_sentences[x])\n","        elif x==3:\n","            sentences_four.append(today_sentences[x])\n","        elif x==4:\n","            sentences_five.append(today_sentences[x])\n","    yesterday=today\n","    \n","#單字副程式\n","def words():\n","    today_word=[]\n","    for i in range(5):\n","        word=push.loc[int(today), '單字'+str(i+1)]\n","        today_word.append(word)\n","    return today_word\n","  \n","#題目編號\n","def numbers():\n","    for a in range(len(X1)):\n","        global yesterday\n","        global today_question\n","        global yesterday_question\n","        if yesterday==None:\n","            yesterday=today\n","        if(X1[a][1] == str(push.loc[int(today), '題目編號']) and X1[a][1] == str(push.loc[int(yesterday), '題目編號'])):\n","            today_question=X1[a][0]\n","            yesterday_question=X1[a][0]\n","        elif(X1[a][1] == str(push.loc[int(today), '題目編號'])):\n","            today_question=X1[a][0]\n","        elif(X1[a][1] == str(push.loc[int(yesterday), '題目編號'])):\n","            yesterday_question=X1[a][0]\n","\n","#題目句子\n","def sentences():\n","    today_sentences=[]\n","    for i in today_word:\n","        check=1\n","        if i in ' '.join(parag_sent[today_question]):\n","            for j in range(len(parag_text[today_question])):\n","                for k in parag_text[today_question][j]:\n","                    if (i in k):\n","                        today_sentences.append(sentence_lists[today_question][j])\n","                        print(k)\n","                        check=0 \n","                        break                    \n","                if check==0:\n","                    break\n","\n","        elif i in ' '.join(parag_sent[yesterday_question]):\n","            for j in range(len(parag_text[yesterday_question])):\n","                for k in parag_text[yesterday_question][j]:\n","                    if (i in k):\n","                        today_sentences.append(sentence_lists[yesterday_question][j])\n","                        print(k)\n","                        check=0\n","                        break                   \n","                if check==0:\n","                    break\n","        else:\n","            today_sentences.append(\"\")\n","    return today_sentences\n","\n","push['句子1']=sentences_one\n","push['句子2']=sentences_two\n","push['句子3']=sentences_three\n","push['句子4']=sentences_four\n","push['句子5']=sentences_five\n","\n","push.reset_index(inplace=True)\n","\n","#存成excel\n","import pandas as pd\n","from pandas import ExcelWriter\n","from pandas import ExcelFile\n","import numpy as np\n","writer = ExcelWriter('單字句子.xlsx')\n","push.to_excel(writer,'Sheet1',index=False)\n","writer.save()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hcSQ5VqdqyQO","colab_type":"text"},"cell_type":"markdown","source":["# 句子填空題"]},{"metadata":{"id":"AB0_kOwVs4-O","colab_type":"code","colab":{}},"cell_type":"code","source":["import pickle\n","with open(\"一星.txt\",'rb') as fp:\n","    X1=pickle.load(fp)\n","    \n","with open(\"斷句DES clear wordsent.txt\",'rb') as fp:\n","    new_wordsent_artickle_list=pickle.load(fp)\n","\n","#製作題目 答案\n","all_Fillinblanks=[]\n","all_answer_Fillinblanks=[]\n","all_sents=[]\n","sentcount=0\n","sentcheck=[]\n","fillblanks=[]\n","fillblanks_check=[]\n","answer_Fillinblanks=[]\n","answer_Fillinblanks_check=[]\n","sents=[]\n","a=0\n","for i in X1:\n","    parag = i[0]\n","    for sent in range(len(new_wordsent_artickle_list[parag])):\n","        if sentcount in range(5):\n","            if sentcheck == []:\n","                sentcheck = new_wordsent_artickle_list[parag][sent]\n","                fillblanks_check=new_wordsent_artickle_list[parag][sent].replace(new_all_answers[parag][sent],\"_______\")\n","                answer_Fillinblanks_check.append(new_all_answers[parag][sent])\n","            elif sentcheck == new_wordsent_artickle_list[parag][sent]:\n","                fillblanks_check=fillblanks_check.replace(new_all_answers[parag][sent],\"_______\")\n","                answer_Fillinblanks_check.append(new_all_answers[parag][sent])\n","            elif sentcheck != new_wordsent_artickle_list[parag][sent]:                \n","                answer_Fillinblanks.append(answer_Fillinblanks_check)\n","                answer_Fillinblanks_check=[]\n","                answer_Fillinblanks_check.append(new_all_answers[parag][sent])\n","                fillblanks.append(fillblanks_check)                              \n","                fillblanks_check=new_wordsent_artickle_list[parag][sent].replace(new_all_answers[parag][sent],\"_______\")\n","                sents.append(sentcheck)\n","                sentcheck = new_wordsent_artickle_list[parag][sent]  \n","                a=1\n","            else:\n","                print('=========')\n","                \n","            if sentcount==4:\n","                answer_Fillinblanks.append(answer_Fillinblanks_check)\n","                all_answer_Fillinblanks.append(answer_Fillinblanks)\n","                fillblanks.append(fillblanks_check)\n","                all_Fillinblanks.append(fillblanks)\n","                sents.append(sentcheck)\n","                all_sents.append(sents)\n","                sentcount=0\n","                sentcheck=[]\n","                fillblanks=[]\n","                fillblanks_check=[]\n","                answer_Fillinblanks=[]\n","                answer_Fillinblanks_check=[]\n","                sents=[]\n","                sents_check=[]\n","                a=0\n","            else: \n","                sentcount=sentcount+1\n","                a=0\n","\n","                \n","#存檔\n","\n","with open(\"填空題目.txt\",'wb') as fp:\n","    pickle.dump(all_Fillinblanks,fp)\n","with open(\"填空題目答案.txt\",'wb') as fp:\n","    pickle.dump(all_answer_Fillinblanks,fp)\n","with open(\"每日句子.txt\",'wb') as fp:\n","    pickle.dump(all_sents,fp)"],"execution_count":0,"outputs":[]}]}